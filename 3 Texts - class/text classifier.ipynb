{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:\n",
    "Классификация текста.\n",
    "Требуется написать программу, которая по отрывку текста сможет сказать,\n",
    "принадлежит ли он перу Льва Толстого или Ильи Ильфа и Евгения Петрова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комментарий:\n",
    "Оптимальной моделью для данной задачи мне представляется классификатор по метрике Term frequency - Inverse document frequency на основе SVM с линейным ядром - классическое, быстрое и эффективное решение. Так как каждый раз margin строится лишь между двумя объектами, линейного ядра вполне достаточно. Дополнительно, мы получаем возможность вывода опорных объектов (слов), что может дать лучшее понимание характера классифицируемых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Python v2.7\n",
    "from sklearn.datasets import load_files\n",
    "text_samples = load_files('Train')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer(max_df = 0.8, ngram_range = (1,2))\n",
    "                      #token_pattern = u'(?u)\\\\b\\\\w\\\\w\\\\w\\\\w+\\\\b')\n",
    "tf_data = tfv.fit_transform(text_samples.data)\n",
    "\n",
    "inv_voc = {v: k for k, v in tfv.vocabulary_.iteritems()} # Inverted vocabulary\n",
    "def get_top10_tfidf(i):\n",
    "    tf_indices = abs(tf_data[i].toarray()[0]).argsort()[-10:]\n",
    "    top_words = [inv_voc[index] for index in tf_indices]\n",
    "    top_words.sort()\n",
    "    print(','.join(top_words))\n",
    "    print(text_samples.target_names[text_samples.target[i]])\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC() # Because 2 classes\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Оптимизация параметра С по GridSearch оказалась бесполезна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\nimport numpy as np\\ngrid = {'C': np.power(10.0, np.arange(-5, 6))}\\ngs = GridSearchCV(clf, grid, scoring='accuracy',\\n                  cv=KFold(n_splits = 5, shuffle = True))\\ngs.fit(tf_data, text_samples.target)\\n\\nfor a in gs.grid_scores_:\\n\\tprint a.mean_validation_score\\n\\tprint a.parameters\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy',\n",
    "                  cv=KFold(n_splits = 5, shuffle = True))\n",
    "gs.fit(tf_data, text_samples.target)\n",
    "\n",
    "for a in gs.grid_scores_:\n",
    "\tprint a.mean_validation_score\n",
    "\tprint a.parameters'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  [0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0] \n",
      "Actual:     [0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 0 0]\n",
      "Accuracy:  1.0\n",
      "Опорные слова\n",
      "Толстой:  сь, мне, то что, de, всё, анна, меня, хаджи, она, жизни\n",
      "Ильф и Петров:  ипполит матвеевич, матвеевич, ипполит, остап, федор, бабский, отец федор, отец, гейнрих, нью\n"
     ]
    }
   ],
   "source": [
    "# C parameter optimization gave no results\n",
    "clf.fit(tf_data, text_samples.target)\n",
    "\n",
    "# Load test samples\n",
    "test_samples = load_files('Test')\n",
    "test_data = tfv.transform(test_samples.data)\n",
    "test_targets = clf.predict(test_data)\n",
    "print 'Predicted: ',test_targets, '\\nActual:    ', test_samples.target\n",
    "print 'Accuracy: ',\\\n",
    "    1 - sum(abs(test_targets - test_samples.target))/float(len(test_targets))\n",
    "'''for i in xrange(len(test_targets)):\n",
    "\tif test_targets[i] != test_samples.target[i]:\n",
    "\t\tprint i, '\\n', test_samples.data[i], '\\n'   '''\n",
    "indices_1 = clf.coef_[0].argsort()[-10:]\n",
    "print 'Опорные слова'\n",
    "print 'Толстой: ', ', '.join([inv_voc[index] for index in indices_1])\n",
    "indices_0 = clf.coef_[0].argsort()[:10]\n",
    "print 'Ильф и Петров: ', ', '.join([inv_voc[index] for index in indices_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация бесполезна для такого типа задач - слишком важна обучающая выборка и её целостность в случае небольшого датасета"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
